services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports: ["2181:2181"]

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on: [zookeeper]
    ports: ["9092:9092"]
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    ports: ["8085:8080"]
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
    depends_on: [kafka]

  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-iot}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
    ports: ["5432:5432"]
    volumes:
      - ./sql/init.sql:/docker-entrypoint-initdb.d/init.sql

  airflow:
    image: apache/airflow:2.9.2
    depends_on: [postgres, kafka]
    environment:
      AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW__CORE__LOAD_EXAMPLES:-False}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:postgres@postgres:5432/iot
      _PIP_ADDITIONAL_REQUIREMENTS: kafka-python==2.0.2 psycopg2-binary==2.9.9 dbt-postgres==1.7.10
      # Uncomment for BigQuery support:
      # _PIP_ADDITIONAL_REQUIREMENTS: kafka-python==2.0.2 psycopg2-binary==2.9.9 dbt-postgres==1.7.10 dbt-bigquery==1.7.7 google-cloud-bigquery==3.11.4
    user: "${AIRFLOW_UID:-50000}:${AIRFLOW_GID:-0}"
    command: >
      bash -c "airflow db migrate &&
               airflow users create --username airflow --password airflow --firstname A --lastname F --role Admin --email admin@example.com &&
               airflow webserver & airflow scheduler"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    ports: ["8080:8080"]

# Uncomment for BigQuery integration:
# volumes:
#   - ./airflow/.env_files/gcp-key.json:/opt/airflow/gcp-key.json:ro
# 
# Then add to airflow service environment:
# GOOGLE_APPLICATION_CREDENTIALS: /opt/airflow/gcp-key.json
# GCP_PROJECT_ID: your-project-id
# BQ_DATASET: iot_pipeline
